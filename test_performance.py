#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
MiniNutriScan æ€§èƒ½æµ‹è¯•å’Œè´Ÿè½½æµ‹è¯•è„šæœ¬
æµ‹è¯•ç³»ç»Ÿå„ä¸ªç»„ä»¶çš„æ€§èƒ½è¡¨ç°å’Œå¹¶å‘å¤„ç†èƒ½åŠ›

ä½œè€…ï¼šAIåŠ©æ‰‹
åˆ›å»ºæ—¶é—´ï¼š2024å¹´
åŠŸèƒ½ï¼šè¯„ä¼°æ•°æ®åº“ã€ç¼“å­˜ã€AIæœåŠ¡ã€OCRæœåŠ¡çš„æ€§èƒ½æŒ‡æ ‡
"""

import os
import sys
import time
import asyncio
import threading
import psutil
import statistics
from concurrent.futures import ThreadPoolExecutor, as_completed
from datetime import datetime
from typing import List, Dict, Any
import requests
import json

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

# å¯¼å…¥é¡¹ç›®æ¨¡å—
try:
    from app.core.database import get_db, test_db_connection, redis_client, test_redis_connection
    from app.services.ai_service import AIService
    from app.services.ocr_service import OCRService
    from app.core.config import settings
except ImportError as e:
    print(f"âŒ å¯¼å…¥æ¨¡å—å¤±è´¥: {e}")
    print("è¯·ç¡®ä¿æ‰€æœ‰ä¾èµ–åŒ…å·²æ­£ç¡®å®‰è£…")
    sys.exit(1)

class PerformanceTester:
    """
    æ€§èƒ½æµ‹è¯•å™¨
    æµ‹è¯•ç³»ç»Ÿå„ä¸ªç»„ä»¶çš„æ€§èƒ½è¡¨ç°å’Œå¹¶å‘å¤„ç†èƒ½åŠ›
    """
    
    def __init__(self):
        self.test_results = []
        self.ai_service = AIService()
        self.ocr_service = OCRService()
        self.start_time = None
        self.system_stats = []
        
    def log_test(self, test_name: str, success: bool, metrics: dict = None, message: str = ""):
        """
        è®°å½•æµ‹è¯•ç»“æœ
        
        Args:
            test_name: æµ‹è¯•åç§°
            success: æ˜¯å¦æˆåŠŸ
            metrics: æ€§èƒ½æŒ‡æ ‡
            message: é™„åŠ ä¿¡æ¯
        """
        result = {
            "test_name": test_name,
            "success": success,
            "message": message,
            "metrics": metrics or {},
            "timestamp": datetime.now().isoformat()
        }
        self.test_results.append(result)
        
        status = "âœ…" if success else "âŒ"
        print(f"{status} {test_name}: {message}")
        if metrics:
            for key, value in metrics.items():
                print(f"   - {key}: {value}")
        print()
    
    def monitor_system_resources(self, duration: int = 60):
        """
        ç›‘æ§ç³»ç»Ÿèµ„æºä½¿ç”¨æƒ…å†µ
        
        Args:
            duration: ç›‘æ§æŒç»­æ—¶é—´ï¼ˆç§’ï¼‰
        """
        print(f"ğŸ” å¼€å§‹ç›‘æ§ç³»ç»Ÿèµ„æºä½¿ç”¨æƒ…å†µï¼ˆ{duration}ç§’ï¼‰...")
        
        start_time = time.time()
        cpu_usage = []
        memory_usage = []
        
        while time.time() - start_time < duration:
            cpu_usage.append(psutil.cpu_percent(interval=1))
            memory_info = psutil.virtual_memory()
            memory_usage.append(memory_info.percent)
            
        metrics = {
            "å¹³å‡CPUä½¿ç”¨ç‡": f"{statistics.mean(cpu_usage):.2f}%",
            "æœ€å¤§CPUä½¿ç”¨ç‡": f"{max(cpu_usage):.2f}%",
            "å¹³å‡å†…å­˜ä½¿ç”¨ç‡": f"{statistics.mean(memory_usage):.2f}%",
            "æœ€å¤§å†…å­˜ä½¿ç”¨ç‡": f"{max(memory_usage):.2f}%"
        }
        
        self.log_test("ç³»ç»Ÿèµ„æºç›‘æ§", True, metrics, "èµ„æºä½¿ç”¨æƒ…å†µç»Ÿè®¡å®Œæˆ")
        return metrics
    
    def test_database_performance(self, num_connections: int = 50, operations_per_connection: int = 10):
        """
        æµ‹è¯•æ•°æ®åº“è¿æ¥æ± æ€§èƒ½
        
        Args:
            num_connections: å¹¶å‘è¿æ¥æ•°
            operations_per_connection: æ¯ä¸ªè¿æ¥çš„æ“ä½œæ¬¡æ•°
        """
        print(f"ğŸ”„ æ‰§è¡Œ æ•°æ®åº“æ€§èƒ½ æµ‹è¯•ï¼ˆ{num_connections}ä¸ªå¹¶å‘è¿æ¥ï¼Œæ¯ä¸ªè¿æ¥{operations_per_connection}æ¬¡æ“ä½œï¼‰...")
        
        def db_operation():
            """å•ä¸ªæ•°æ®åº“æ“ä½œ"""
            start_time = time.time()
            try:
                # æµ‹è¯•æ•°æ®åº“è¿æ¥
                success = test_db_connection()
                end_time = time.time()
                return success, end_time - start_time
            except Exception as e:
                end_time = time.time()
                return False, end_time - start_time
        
        start_time = time.time()
        response_times = []
        success_count = 0
        total_operations = num_connections * operations_per_connection
        
        with ThreadPoolExecutor(max_workers=num_connections) as executor:
            futures = []
            for _ in range(total_operations):
                future = executor.submit(db_operation)
                futures.append(future)
            
            for future in as_completed(futures):
                success, response_time = future.result()
                response_times.append(response_time)
                if success:
                    success_count += 1
        
        end_time = time.time()
        total_time = end_time - start_time
        
        metrics = {
            "æ€»æ“ä½œæ•°": total_operations,
            "æˆåŠŸæ“ä½œæ•°": success_count,
            "æˆåŠŸç‡": f"{(success_count/total_operations)*100:.2f}%",
            "æ€»è€—æ—¶": f"{total_time:.3f}ç§’",
            "å¹³å‡å“åº”æ—¶é—´": f"{statistics.mean(response_times)*1000:.2f}ms",
            "æœ€å¤§å“åº”æ—¶é—´": f"{max(response_times)*1000:.2f}ms",
            "æœ€å°å“åº”æ—¶é—´": f"{min(response_times)*1000:.2f}ms",
            "ååé‡": f"{total_operations/total_time:.2f} ops/sec"
        }
        
        success = success_count > total_operations * 0.95  # 95%æˆåŠŸç‡ä¸ºé€šè¿‡
        message = "æ•°æ®åº“æ€§èƒ½æµ‹è¯•å®Œæˆ" if success else "æ•°æ®åº“æ€§èƒ½æµ‹è¯•å­˜åœ¨é—®é¢˜"
        self.log_test("æ•°æ®åº“æ€§èƒ½æµ‹è¯•", success, metrics, message)
        
        return metrics
    
    def test_redis_performance(self, num_operations: int = 1000, concurrent_clients: int = 20):
        """
        æµ‹è¯•Redisç¼“å­˜æ€§èƒ½
        
        Args:
            num_operations: æ“ä½œæ€»æ•°
            concurrent_clients: å¹¶å‘å®¢æˆ·ç«¯æ•°
        """
        print(f"ğŸ”„ æ‰§è¡Œ Redisç¼“å­˜æ€§èƒ½ æµ‹è¯•ï¼ˆ{num_operations}æ¬¡æ“ä½œï¼Œ{concurrent_clients}ä¸ªå¹¶å‘å®¢æˆ·ç«¯ï¼‰...")
        
        def redis_operation(operation_id: int):
            """å•ä¸ªRedisæ“ä½œ"""
            start_time = time.time()
            try:
                # æµ‹è¯•å†™å…¥
                key = f"perf_test_{operation_id}"
                value = f"test_value_{operation_id}_{time.time()}"
                redis_client.set(key, value, ex=60)  # 60ç§’è¿‡æœŸ
                
                # æµ‹è¯•è¯»å–
                retrieved_value = redis_client.get(key)
                
                # æµ‹è¯•åˆ é™¤
                redis_client.delete(key)
                
                end_time = time.time()
                return True, end_time - start_time
            except Exception as e:
                end_time = time.time()
                return False, end_time - start_time
        
        start_time = time.time()
        response_times = []
        success_count = 0
        
        with ThreadPoolExecutor(max_workers=concurrent_clients) as executor:
            futures = []
            for i in range(num_operations):
                future = executor.submit(redis_operation, i)
                futures.append(future)
            
            for future in as_completed(futures):
                success, response_time = future.result()
                response_times.append(response_time)
                if success:
                    success_count += 1
        
        end_time = time.time()
        total_time = end_time - start_time
        
        metrics = {
            "æ€»æ“ä½œæ•°": num_operations,
            "æˆåŠŸæ“ä½œæ•°": success_count,
            "æˆåŠŸç‡": f"{(success_count/num_operations)*100:.2f}%",
            "æ€»è€—æ—¶": f"{total_time:.3f}ç§’",
            "å¹³å‡å“åº”æ—¶é—´": f"{statistics.mean(response_times)*1000:.2f}ms",
            "æœ€å¤§å“åº”æ—¶é—´": f"{max(response_times)*1000:.2f}ms",
            "æœ€å°å“åº”æ—¶é—´": f"{min(response_times)*1000:.2f}ms",
            "ååé‡": f"{num_operations/total_time:.2f} ops/sec"
        }
        
        success = success_count > num_operations * 0.95  # 95%æˆåŠŸç‡ä¸ºé€šè¿‡
        message = "Redisæ€§èƒ½æµ‹è¯•å®Œæˆ" if success else "Redisæ€§èƒ½æµ‹è¯•å­˜åœ¨é—®é¢˜"
        self.log_test("Redisç¼“å­˜æ€§èƒ½æµ‹è¯•", success, metrics, message)
        
        return metrics
    
    def test_ai_service_performance(self, num_requests: int = 20, concurrent_requests: int = 5):
        """
        æµ‹è¯•AIæœåŠ¡æ€§èƒ½
        
        Args:
            num_requests: è¯·æ±‚æ€»æ•°
            concurrent_requests: å¹¶å‘è¯·æ±‚æ•°
        """
        print(f"ğŸ”„ æ‰§è¡Œ AIæœåŠ¡æ€§èƒ½ æµ‹è¯•ï¼ˆ{num_requests}æ¬¡è¯·æ±‚ï¼Œ{concurrent_requests}ä¸ªå¹¶å‘è¯·æ±‚ï¼‰...")
        
        def ai_request():
            """å•ä¸ªAIè¯·æ±‚"""
            start_time = time.time()
            try:
                # æ¨¡æ‹Ÿè¥å…»åˆ†æè¯·æ±‚
                test_data = {
                    "food_name": "è‹¹æœ",
                    "nutrition": {
                        "energy": 52,
                        "protein": 0.3,
                        "fat": 0.2,
                        "carbohydrate": 13.8
                    }
                }
                
                # è°ƒç”¨AIåˆ†æï¼ˆä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®é¿å…å®é™…APIè°ƒç”¨ï¼‰
                result = self.ai_service.analyze_nutrition_mock(test_data)
                
                end_time = time.time()
                return True, end_time - start_time
            except Exception as e:
                end_time = time.time()
                return False, end_time - start_time
        
        start_time = time.time()
        response_times = []
        success_count = 0
        
        with ThreadPoolExecutor(max_workers=concurrent_requests) as executor:
            futures = []
            for _ in range(num_requests):
                future = executor.submit(ai_request)
                futures.append(future)
            
            for future in as_completed(futures):
                success, response_time = future.result()
                response_times.append(response_time)
                if success:
                    success_count += 1
        
        end_time = time.time()
        total_time = end_time - start_time
        
        if response_times:
            metrics = {
                "æ€»è¯·æ±‚æ•°": num_requests,
                "æˆåŠŸè¯·æ±‚æ•°": success_count,
                "æˆåŠŸç‡": f"{(success_count/num_requests)*100:.2f}%",
                "æ€»è€—æ—¶": f"{total_time:.3f}ç§’",
                "å¹³å‡å“åº”æ—¶é—´": f"{statistics.mean(response_times)*1000:.2f}ms",
                "æœ€å¤§å“åº”æ—¶é—´": f"{max(response_times)*1000:.2f}ms",
                "æœ€å°å“åº”æ—¶é—´": f"{min(response_times)*1000:.2f}ms",
                "ååé‡": f"{num_requests/total_time:.2f} req/sec"
            }
        else:
            metrics = {
                "æ€»è¯·æ±‚æ•°": num_requests,
                "æˆåŠŸè¯·æ±‚æ•°": 0,
                "æˆåŠŸç‡": "0.00%",
                "é”™è¯¯": "æ‰€æœ‰è¯·æ±‚éƒ½å¤±è´¥äº†"
            }
        
        success = success_count > 0
        message = "AIæœåŠ¡æ€§èƒ½æµ‹è¯•å®Œæˆ" if success else "AIæœåŠ¡æ€§èƒ½æµ‹è¯•å¤±è´¥"
        self.log_test("AIæœåŠ¡æ€§èƒ½æµ‹è¯•", success, metrics, message)
        
        return metrics
    
    def test_concurrent_load(self, duration: int = 30, concurrent_users: int = 10):
        """
        æµ‹è¯•å¹¶å‘è´Ÿè½½å¤„ç†èƒ½åŠ›
        
        Args:
            duration: æµ‹è¯•æŒç»­æ—¶é—´ï¼ˆç§’ï¼‰
            concurrent_users: å¹¶å‘ç”¨æˆ·æ•°
        """
        print(f"ğŸ”„ æ‰§è¡Œ å¹¶å‘è´Ÿè½½ æµ‹è¯•ï¼ˆ{duration}ç§’ï¼Œ{concurrent_users}ä¸ªå¹¶å‘ç”¨æˆ·ï¼‰...")
        
        def simulate_user_activity():
            """æ¨¡æ‹Ÿç”¨æˆ·æ´»åŠ¨"""
            operations = []
            start_time = time.time()
            
            while time.time() - start_time < duration:
                # æ¨¡æ‹Ÿä¸åŒç±»å‹çš„æ“ä½œ
                operation_start = time.time()
                
                try:
                    # éšæœºé€‰æ‹©æ“ä½œç±»å‹
                    import random
                    operation_type = random.choice(["db", "redis", "ai"])
                    
                    if operation_type == "db":
                        success = test_db_connection()
                    elif operation_type == "redis":
                        key = f"load_test_{random.randint(1, 1000)}"
                        redis_client.set(key, "test_value", ex=10)
                        redis_client.get(key)
                        redis_client.delete(key)
                        success = True
                    else:  # ai
                        # æ¨¡æ‹ŸAIè°ƒç”¨
                        time.sleep(0.1)  # æ¨¡æ‹ŸAIå¤„ç†æ—¶é—´
                        success = True
                    
                    operation_end = time.time()
                    operations.append({
                        "type": operation_type,
                        "success": success,
                        "duration": operation_end - operation_start
                    })
                    
                except Exception as e:
                    operation_end = time.time()
                    operations.append({
                        "type": operation_type,
                        "success": False,
                        "duration": operation_end - operation_start,
                        "error": str(e)
                    })
                
                # çŸ­æš‚ä¼‘æ¯æ¨¡æ‹ŸçœŸå®ç”¨æˆ·è¡Œä¸º
                time.sleep(0.1)
            
            return operations
        
        start_time = time.time()
        all_operations = []
        
        with ThreadPoolExecutor(max_workers=concurrent_users) as executor:
            futures = []
            for _ in range(concurrent_users):
                future = executor.submit(simulate_user_activity)
                futures.append(future)
            
            for future in as_completed(futures):
                user_operations = future.result()
                all_operations.extend(user_operations)
        
        end_time = time.time()
        total_time = end_time - start_time
        
        # ç»Ÿè®¡ç»“æœ
        total_operations = len(all_operations)
        successful_operations = sum(1 for op in all_operations if op["success"])
        
        if all_operations:
            response_times = [op["duration"] for op in all_operations]
            
            # æŒ‰æ“ä½œç±»å‹ç»Ÿè®¡
            db_ops = [op for op in all_operations if op["type"] == "db"]
            redis_ops = [op for op in all_operations if op["type"] == "redis"]
            ai_ops = [op for op in all_operations if op["type"] == "ai"]
            
            metrics = {
                "æµ‹è¯•æŒç»­æ—¶é—´": f"{total_time:.3f}ç§’",
                "å¹¶å‘ç”¨æˆ·æ•°": concurrent_users,
                "æ€»æ“ä½œæ•°": total_operations,
                "æˆåŠŸæ“ä½œæ•°": successful_operations,
                "æˆåŠŸç‡": f"{(successful_operations/total_operations)*100:.2f}%",
                "å¹³å‡å“åº”æ—¶é—´": f"{statistics.mean(response_times)*1000:.2f}ms",
                "æœ€å¤§å“åº”æ—¶é—´": f"{max(response_times)*1000:.2f}ms",
                "ååé‡": f"{total_operations/total_time:.2f} ops/sec",
                "æ•°æ®åº“æ“ä½œæ•°": len(db_ops),
                "Redisæ“ä½œæ•°": len(redis_ops),
                "AIæ“ä½œæ•°": len(ai_ops)
            }
        else:
            metrics = {
                "é”™è¯¯": "æ²¡æœ‰å®Œæˆä»»ä½•æ“ä½œ",
                "å¹¶å‘ç”¨æˆ·æ•°": concurrent_users,
                "æµ‹è¯•æŒç»­æ—¶é—´": f"{total_time:.3f}ç§’"
            }
        
        success = successful_operations > total_operations * 0.90  # 90%æˆåŠŸç‡ä¸ºé€šè¿‡
        message = "å¹¶å‘è´Ÿè½½æµ‹è¯•å®Œæˆ" if success else "å¹¶å‘è´Ÿè½½æµ‹è¯•å­˜åœ¨é—®é¢˜"
        self.log_test("å¹¶å‘è´Ÿè½½æµ‹è¯•", success, metrics, message)
        
        return metrics
    
    def run_performance_test(self):
        """
        è¿è¡Œå®Œæ•´çš„æ€§èƒ½æµ‹è¯•å¥—ä»¶
        """
        print("="*80)
        print("ğŸš€ MiniNutriScan æ€§èƒ½æµ‹è¯•å’Œè´Ÿè½½æµ‹è¯•å¼€å§‹")
        print("="*80)
        print()
        
        self.start_time = time.time()
        
        # 1. ç³»ç»Ÿèµ„æºç›‘æ§ï¼ˆåå°è¿è¡Œï¼‰
        monitor_thread = threading.Thread(
            target=lambda: self.monitor_system_resources(60),
            daemon=True
        )
        monitor_thread.start()
        
        # 2. æ•°æ®åº“æ€§èƒ½æµ‹è¯•
        try:
            self.test_database_performance(num_connections=20, operations_per_connection=5)
        except Exception as e:
            self.log_test("æ•°æ®åº“æ€§èƒ½æµ‹è¯•", False, {}, f"æµ‹è¯•å¼‚å¸¸: {str(e)}")
        
        # 3. Redisç¼“å­˜æ€§èƒ½æµ‹è¯•
        try:
            self.test_redis_performance(num_operations=500, concurrent_clients=10)
        except Exception as e:
            self.log_test("Redisç¼“å­˜æ€§èƒ½æµ‹è¯•", False, {}, f"æµ‹è¯•å¼‚å¸¸: {str(e)}")
        
        # 4. AIæœåŠ¡æ€§èƒ½æµ‹è¯•
        try:
            self.test_ai_service_performance(num_requests=10, concurrent_requests=3)
        except Exception as e:
            self.log_test("AIæœåŠ¡æ€§èƒ½æµ‹è¯•", False, {}, f"æµ‹è¯•å¼‚å¸¸: {str(e)}")
        
        # 5. å¹¶å‘è´Ÿè½½æµ‹è¯•
        try:
            self.test_concurrent_load(duration=20, concurrent_users=5)
        except Exception as e:
            self.log_test("å¹¶å‘è´Ÿè½½æµ‹è¯•", False, {}, f"æµ‹è¯•å¼‚å¸¸: {str(e)}")
        
        # ç­‰å¾…ç³»ç»Ÿç›‘æ§å®Œæˆ
        monitor_thread.join(timeout=5)
        
        # ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š
        self.generate_performance_report()
    
    def generate_performance_report(self):
        """
        ç”Ÿæˆæ€§èƒ½æµ‹è¯•æŠ¥å‘Š
        """
        end_time = time.time()
        total_time = end_time - self.start_time
        
        print("="*80)
        print("ğŸ“Š æ€§èƒ½æµ‹è¯•ç»“æœæ±‡æ€»")
        print("="*80)
        
        passed_tests = sum(1 for result in self.test_results if result["success"])
        total_tests = len(self.test_results)
        success_rate = (passed_tests / total_tests * 100) if total_tests > 0 else 0
        
        print(f"æ€»æµ‹è¯•æ•°: {total_tests}")
        print(f"é€šè¿‡æµ‹è¯•: {passed_tests} âœ…")
        print(f"å¤±è´¥æµ‹è¯•: {total_tests - passed_tests} âŒ")
        print(f"æˆåŠŸç‡: {success_rate:.1f}%")
        print(f"æ€»è€—æ—¶: {total_time:.2f}ç§’")
        print()
        
        print("ğŸ“‹ è¯¦ç»†æµ‹è¯•ç»“æœ:")
        for result in self.test_results:
            status = "âœ…" if result["success"] else "âŒ"
            print(f"   {status} {result['test_name']}: {result['message']}")
            
            # æ˜¾ç¤ºå…³é”®æ€§èƒ½æŒ‡æ ‡
            if result["metrics"]:
                key_metrics = ["æˆåŠŸç‡", "å¹³å‡å“åº”æ—¶é—´", "ååé‡", "å¹³å‡CPUä½¿ç”¨ç‡", "å¹³å‡å†…å­˜ä½¿ç”¨ç‡"]
                for metric in key_metrics:
                    if metric in result["metrics"]:
                        print(f"      - {metric}: {result['metrics'][metric]}")
        
        print()
        
        # æ€§èƒ½è¯„ä¼°
        if success_rate >= 80:
            print("ğŸ‰ æ€§èƒ½æµ‹è¯•æ•´ä½“è¡¨ç°è‰¯å¥½")
        elif success_rate >= 60:
            print("âš ï¸  æ€§èƒ½æµ‹è¯•å­˜åœ¨ä¸€äº›é—®é¢˜ï¼Œå»ºè®®ä¼˜åŒ–")
        else:
            print("âŒ æ€§èƒ½æµ‹è¯•å­˜åœ¨ä¸¥é‡é—®é¢˜ï¼Œéœ€è¦ç«‹å³å¤„ç†")
        
        # ä¿å­˜è¯¦ç»†æŠ¥å‘Šåˆ°æ–‡ä»¶
        self.save_performance_report()
        
        print("="*80)
        print("ğŸ æ€§èƒ½æµ‹è¯•å’Œè´Ÿè½½æµ‹è¯•å®Œæˆ")
        print("="*80)
    
    def save_performance_report(self):
        """
        ä¿å­˜æ€§èƒ½æµ‹è¯•æŠ¥å‘Šåˆ°æ–‡ä»¶
        """
        try:
            report_data = {
                "test_time": datetime.now().isoformat(),
                "total_duration": time.time() - self.start_time,
                "test_results": self.test_results,
                "summary": {
                    "total_tests": len(self.test_results),
                    "passed_tests": sum(1 for r in self.test_results if r["success"]),
                    "success_rate": (sum(1 for r in self.test_results if r["success"]) / len(self.test_results) * 100) if self.test_results else 0
                }
            }
            
            report_file = f"performance_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
            with open(report_file, 'w', encoding='utf-8') as f:
                json.dump(report_data, f, ensure_ascii=False, indent=2)
            
            print(f"ğŸ“„ è¯¦ç»†æ€§èƒ½æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_file}")
            
        except Exception as e:
            print(f"âš ï¸  ä¿å­˜æ€§èƒ½æŠ¥å‘Šå¤±è´¥: {str(e)}")

# ä¸ºAIæœåŠ¡æ·»åŠ æ¨¡æ‹Ÿæ–¹æ³•
class MockAIService:
    """æ¨¡æ‹ŸAIæœåŠ¡ç”¨äºæ€§èƒ½æµ‹è¯•"""
    
    def analyze_nutrition_mock(self, data):
        """æ¨¡æ‹Ÿè¥å…»åˆ†æ"""
        # æ¨¡æ‹Ÿå¤„ç†æ—¶é—´
        time.sleep(0.05)  # 50msæ¨¡æ‹Ÿå¤„ç†æ—¶é—´
        
        return {
            "analysis": "æ¨¡æ‹Ÿè¥å…»åˆ†æç»“æœ",
            "health_score": 85,
            "recommendations": ["å»ºè®®å¢åŠ è›‹ç™½è´¨æ‘„å…¥", "æ³¨æ„æ§åˆ¶ç³–åˆ†"]
        }

# æ‰©å±•AIæœåŠ¡ç±»
if 'AIService' in globals():
    AIService.analyze_nutrition_mock = MockAIService().analyze_nutrition_mock

def main():
    """
    ä¸»å‡½æ•°ï¼šæ‰§è¡Œæ€§èƒ½æµ‹è¯•
    """
    try:
        tester = PerformanceTester()
        tester.run_performance_test()
    except KeyboardInterrupt:
        print("\nâš ï¸  æµ‹è¯•è¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"âŒ æ€§èƒ½æµ‹è¯•æ‰§è¡Œå¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()